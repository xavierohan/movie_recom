{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_movies = pd.read_csv('/kaggle/input/data-large/df_large.csv')\ndf_ratings = pd.read_csv('/kaggle/input/data-large/d_large.csv')\nratings = pd.read_csv('/kaggle/input/the-movies-dataset/ratings_small.csv')  # remove _small\npd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame containing movie info\ndel df_movies['overview']\ndf_movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame containing user ratings\ndf_ratings.rename(columns = {'id':'MovieId'}, inplace = True)\ndf_ratings = df_ratings[['userId', 'MovieId', 'title', 'genres', 'keywords', 'rating']]\ndf_ratings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = df_ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Size of ratings dataframe: \",len(ratings), \"  Size of movies dataframe: \",len(df_movies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ast import literal_eval\n# To return the first 3 genres\ndf_movies['genres'] = df_movies['genres'].apply(literal_eval).apply(lambda x : x[0:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_movies['Unnamed: 0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the genres to seperate columns\ndf_movies[['genre1','genre2', 'genre3']] = pd.DataFrame(df_movies.genres.tolist(), index= df_movies.index)\ndf_movies.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop movies that do not have two genre values\nn = len(df_movies)\ndf_movies.dropna(subset = [\"genre1\", \"genre2\"], inplace=True)\n\nprint(\"Size of DataFrame after dropping movies that do not have 2 genre valus : \",len(df_movies))\nprint(\"Number of movies dropped: \", n - len(df_movies))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map genre1 to integer values\ngenre1_list = np.unique(df_movies.genre1) \ng1_dict = {k: int(v) for v, k in enumerate(genre1_list)}\ng1_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map genre2 to integer values\ngenre2_list = np.unique(df_movies.genre2) \ng2_dict = {k: int(v) for v, k in enumerate(genre2_list)}\ng2_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace categorical values of genre with integer values\ndf_movies = df_movies.replace({\"genre1\": g1_dict, \"genre2\": g2_dict})\ndf_movies.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = ratings.rename(columns={'movieId': 'id'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge ratings and df_movies based on movieid\nd = pd.merge(ratings, df_movies, on ='id' )\nd.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del ratings\ndel d['timestamp']\ndel d['popularity']\ndel d['release_date']\ndel d['actors']\ndel d['director']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mapping the movieid to continous targets, as there are breaks between ids\nt = dict([(y,x) for x,y in enumerate(np.unique(d['id']))])\nd['id'] = d['id'].map(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# starting userId from 0\nd['userId'] = d['userId'] - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the most common movie keywords\n\nimport ast\ntemp =[]\nfor i in d['keywords']:\n    res = ast.literal_eval(i) \n    temp.extend(res)\n\nprint(len(temp))\n\nfrom collections import Counter \nCounter = Counter(temp)\nmost_occur = Counter.most_common(1500) #1500\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert most common keywords to integer values\n\nk = dict([(y[0],x) for x,y in enumerate(most_occur)])\nf = []\nfor i in d['keywords']:\n    temp = []\n    for j in ast.literal_eval(i):\n        if j in k.keys() and len(temp) < 3:\n            temp.append(k[j])\n            \n    f.append(temp)\n    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['key'] = f\nd.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['key_count'] = d['key'].apply(lambda x: len(x))\nprint(\"Size before dropping: \",len(d))\nd = d[d['key_count'] >1] # Drop movies that have less than one most common keywords\nprint(\"Size of DataFrame after dropping : \",len(d))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create columns based on keyword integer value\nd[['key1','key2', 'key3']] = pd.DataFrame(d.key.tolist(), index= d.index)\nd.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map the Keyword values to continous values starting from 0\n\nkey_list = np.unique(list(np.unique(d['key1'])) + list(np.unique(d['key2'])))\n\nt = dict([(y,x) for x,y in enumerate(key_list)])\n\nd = d.replace({\"key1\": t, \"key2\":t}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del d['genre3']\ndel d['key']\ndel d['key_count']\ndel d['key3']\nd[d['title']=='The Godfather'].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique movies : \",len(np.unique(d['id'])),\"\\nNumber of unique users: \", len(np.unique(d['userId'])),\"\\nTotal Number of enteries in the DataFrame: \", len(d))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\n\nhidden_units = (32,4)\n#movie_embedding_size = 50\n#user_embedding_size = 50\nm_emb_size = min(len(np.unique(d.id))//2 , 50)\nu_emb_size = min(len(np.unique(d.userId))//2 , 50)\ng1_emb_size = min(len(np.unique(d.genre1))//2 , 50)\ng2_emb_size = min(len(np.unique(d.genre2))//2 , 50)\nk1_emb_size = min(len(np.unique(d.key1))//2 , 50)\nk2_emb_size = min(len(np.unique(d.key2))//2 , 50)\n\n\n# Each instance will consist of two inputs: a single user id, and a single movie id\nuser_id_input = keras.Input(shape=(1,), name='user_id')\nmovie_id_input = keras.Input(shape=(1,) ,name='movie_id')\n\ng1_id_input = keras.Input(shape = (1,), name='g1_id' )\ng2_id_input = keras.Input(shape = (1,), name='g2_id' )\n\nk1_id_input = keras.Input(shape = (1,), name='k1_id' )\nk2_id_input = keras.Input(shape = (1,), name='k2_id' )\n#director_input = keras\n\n\nuser_embedded = keras.layers.Embedding(d.userId.max()+1, m_emb_size, \n                                       input_length=1, name='user_embedding')(user_id_input)\nmovie_embedded = keras.layers.Embedding(d.id.max()+1, u_emb_size, \n                                        input_length=1, name='movie_embedding')(movie_id_input)\n\ng1_embedded = keras.layers.Embedding(d.genre1.max()+1, g1_emb_size, \n                                        input_length=1, name='genre1_embedding')(g1_id_input)\ng2_embedded = keras.layers.Embedding(d.genre2.max()+1, g2_emb_size, \n                                       input_length=1, name='genre2_embedding')(g2_id_input)\n\nk1_embedded = keras.layers.Embedding(d.key1.max()+1, k1_emb_size, \n                                        input_length=1, name='key1_embedding')(k1_id_input)\nk2_embedded = keras.layers.Embedding(d.key2.max()+1, k2_emb_size, \n                                       input_length=1, name='key2_embedding')(k2_id_input)\n\n\n# Concatenate the embeddings (and remove the useless extra dimension)\nconcatenated = keras.layers.Concatenate()([user_embedded, movie_embedded, g1_embedded, g2_embedded, k1_embedded, k2_embedded])\nout = keras.layers.Flatten()(concatenated)\n\nfrom keras import backend as K\n\ndef custom_activation(x):\n    return (K.sigmoid(x) * 6) \n\n# Add one or more hidden layers\nfor n_hidden in hidden_units:\n    out = keras.layers.Dense(n_hidden, activation='relu')(out)\n    out = keras.layers.Dropout(0.2)(out)\n    #out = keras.layers.Dense(n_hidden, activation=custom_activation)(out)\n\n# A single output: our predicted rating\nout = keras.layers.Dense(1, activation= custom_activation, name='prediction')(out) #'linear'\n\nmodel2 = keras.Model(\n    inputs = [user_id_input, movie_id_input, g1_id_input, g2_id_input, k1_id_input, k2_id_input],\n    outputs = out,\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nmodel2.compile(keras.optimizers.Adam(learning_rate=0.01),\n    loss='MSE',\n    metrics=['mse', 'mae', 'mape'])\n\nhistory = model2.fit(\n    [d.userId, d.id, d.genre1, d.genre2, d.key1, d.key2],\n    d.rating,\n    batch_size=2000,\n    epochs=100,\n    verbose=0,\n    validation_split=.1,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Saved Model\n\nfrom keras import backend as K\n\ndef custom_activation(x):\n    return (K.sigmoid(x) * 6) \n\nfrom keras.models import load_model\n\n# To load the model\ncustom_objects={'custom_activation': custom_activation}\n\n# To load a persisted model that uses the CRF layer \nmodel2 = load_model(\"/kaggle/input/model/Startwars_188.h5\", custom_objects = custom_objects)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.keras.utils.plot_model(model2, to_file='Embedding_Model.png', show_shapes=True, show_layer_names=False)\nfrom IPython.display import Image\nImage(retina=False, filename='Embedding_Model.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MODEL PERFORMANCE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = d[['userId', 'id', 'genre1','genre2', 'rating', 'key1','key2']]\ny = d['rating']\n\nX['pred'] = model2.predict([[X['userId']], [X['id']],[X['genre1']],[X['genre2']], [X['key1']], [X['key2']]])\n\nX['diff'] = abs(X['rating'] - X['pred'])\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\nMSE = mean_squared_error(y_true = X.rating.values, y_pred = X.pred.values )\nMAE = mean_absolute_error(y_true = X.rating.values, y_pred = X.pred.values )\n\nprint(\"MEAN SQUARED ERROR : \", MSE, \"\\nROOT MEAN SQUARED ERROR : \", MSE**(0.5), \"\\nMEAN ABSOLUTE ERROR : \", MAE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Movie Embedding Vector\nemb_layer = model2.get_layer('movie_embedding')\n(w,) = emb_layer.get_weights()\nw[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Recommendations**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nmslib\nimport nmslib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Searching in Embedding Space\n\nmovies_index = nmslib.init(space='angulardist', method='hnsw')\nmovies_index.addDataPointBatch(model2.get_layer('movie_embedding').get_weights()[0])\n\nuser_index = nmslib.init(space='angulardist', method='hnsw')\nuser_index.addDataPointBatch(model2.get_layer('user_embedding').get_weights()[0])\n\nM = 100\nefC = 1000\nefS = 1000\nnum_threads = 6\nindex_time_params = {'M': M, 'indexThreadQty': num_threads, 'efConstruction': efC, 'post' : 0}\nquery_time_params = {'efSearch': efS}\n\nmovies_index.createIndex(index_time_params)\nmovies_index.setQueryTimeParams(query_time_params)\n\nuser_index.createIndex(index_time_params)\nuser_index.setQueryTimeParams(query_time_params)\n\ndef get_knns(index, vecs, n_neighbour):\n     return zip(*index.knnQueryBatch(vecs, k=n_neighbour, num_threads=6))\n\ndef get_knn(index, vec, n_neighbour):\n    return index.knnQuery(vec, k=n_neighbour)\n\ndef suggest_movies_knn(movieId, n_suggest = 5):\n    id = movieId\n    res = get_knn(movies_index, model2.get_layer(\"movie_embedding\").get_weights()[0][movieId], n_suggest)[0]\n    #return df_main[df_main.id.isin([idx2movie[i] for i in res])]\n    return res\n    \ndef suggest_users_knn(userId, n_suggest = 5):\n    i = userId\n    res = get_knn(user_index, model2.get_layer(\"user_embedding\").get_weights()[0][userId], n_suggest)[0]\n    #return df_main[df_main.id.isin([idx2movie[i] for i in res])]\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[d['title']=='Star Wars'].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recommendations for Star Wars\nmovie_id = 188 # 188 --> Star Wars\nj = suggest_movies_knn(movie_id, 8)\nprint(\" Recommended Movies based on Movie Embedding are : \\n\",list(np.unique(d[d['id'].isin(j)]['title'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[d['title']=='The Lord of the Rings: The Fellowship of the Ring'].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_id = 3087 # 3087 --> The Lord of the Rings: The Fellowship of the Ring\nj = suggest_movies_knn(movie_id, 8)\nprint(\" Recommended Movies based on Movie Embedding are : \\n\",list(np.unique(d[d['id'].isin(j)]['title'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[(d['userId']==288) & (d['rating']>4)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recommend similar profiles\nuser_id = 288\nj = suggest_users_knn(user_id, 5)\nprint(\" Recommended Users based on user Embedding are : \\n\",list(np.unique(d[d['userId'].isin(j)]['userId']))[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recommendations Based on User Profile #288\nuser_id = 288\nuser_profile = d[d['userId'] == user_id]  \nuser_profile = user_profile[['userId', 'id', 'title', 'genre1', 'genre2', 'key1', 'key2', 'rating', 'genres']]\nuser_profile = user_profile[user_profile['rating']>4]\nuser_profile # User Profile of user 288","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the average movie embedding to capture user interests.\navg_w = 0\nfor i in user_profile.id:\n    avg_w += w[i]\navg_w = avg_w/len(user_profile)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recommending movies based on average movie embedding\nj= get_knn(movies_index, avg_w , 5)[0]\nprint(\" Recommended Movies based on Movie Embedding are : \\n\",list(np.unique(d[d['id'].isin(j)]['title'])))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}